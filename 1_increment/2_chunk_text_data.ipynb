{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Imports",
   "id": "82c01f52e7f15124"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-14T20:05:29.983713Z",
     "start_time": "2025-07-14T20:05:29.969742Z"
    }
   },
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter   import RecursiveCharacterTextSplitter\n",
    "import streamlit as st\n",
    "from langchain.vectorstores import FAISS"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. chunk the text created in 1_webcrawling",
   "id": "dbaf595a1f39631c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T20:05:30.046627Z",
     "start_time": "2025-07-14T20:05:29.993578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TEXT_PATH = \"data/all_text.txt\"   # the file you wrote earlier\n",
    "\n",
    "# ─── 3)  load the whole file into one LangChain Document ─────────────────────────\n",
    "loader = TextLoader(TEXT_PATH, encoding=\"utf-8\")\n",
    "docs   = loader.load()                  # → [Document(page_content=..., metadata={'source': TEXT_PATH})]\n",
    "\n",
    "# ─── 4)  split into overlapping chunks ───────────────────────────────────────────\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size     = 1000,   # characters per chunk\n",
    "    chunk_overlap  = 200,    # to give the model context continuity\n",
    "    separators     = [\"\\n\\n\", \"\\n\", \" \", \"\"],  # big → small\n",
    ")\n",
    "chunks = splitter.split_documents(docs)   # list[Document]\n",
    "\n",
    "print(f\"{len(chunks)=}\")\n",
    "print(chunks[0].page_content[:300] + \" [...]\")"
   ],
   "id": "9272139c820304cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(chunks)=1203\n",
      "# https://wiki.student.uni-goettingen.de/start [...]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. create embeddings",
   "id": "da6201c646e23cca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T20:11:58.173517Z",
     "start_time": "2025-07-14T20:05:30.070400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helper.academicCloudEmbeddings import AcademicCloudEmbeddings\n",
    "\n",
    "embedder = AcademicCloudEmbeddings(api_key=st.secrets[\"GWDG_API_KEY\"], url=st.secrets[\"BASE_URL_EMBEDDINGS\"])\n",
    "store = FAISS.from_documents(chunks, embedder)\n",
    "store.save_local(\"faiss_wiki_index\")      # → folder with index"
   ],
   "id": "9fbbbc2cfc40c6ce",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
